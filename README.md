# final-project-in-the-cloud
## Finding Solutions in Differential Privacy

#### Anchita Bora and Nicole Carter

Our project focuses on 3 solutions for differential privacy and the the consequences of using users’ personal data. In the research papers that we’ve found, we have seen the implementation of different algorithms to combat the main problem of endangering the personal data of users when their information is being used to calculate statistics for big companies.

Differential privacy is a mathematical technique that adds a certain level of randomness to a dataset to prevent anyone from getting information from a dataset. This allows the final dataset to be accurate enough to garner insights into the individuals in data analysis while protecting the privacy of the individuals’ data.

We are concerened with 3 algorithms: 
  * Report Noisy Max
  * Sparse Vector Method
  * Histogram
  
Research Papers:
  * _[Detecting Violations of Differential Privacy](https://arxiv.org/abs/1805.10277)_
  * _[Differential Privacy: A Survey of Results](https://link.springer.com/chapter/10.1007/978-3-540-79228-4_1)_
  * _[Differential Privacy and Machine Learning: A Survey and Review](https://arxiv.org/pdf/1412.7584.pdf?source=post_page---------------------------)_

For more information about our findings, please visit our slides here 
[Project Slide Deck](https://docs.google.com/presentation/d/1XbKV2ph05kceU0qGW0UEU9zfl4x__w6X/edit?usp=sharing&ouid=110762060930354783887&rtpof=true&sd=true).
